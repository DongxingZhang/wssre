<div class="blk_container">
    <p>
        AI加速需求超过CPU计算能力摩尔定律供给。深度学习是目前AI领域最有效算法,深度学习模型需要通过大量的数据训练才能获得理想的效果,CPU优势为处理各类数据及强逻辑判断能力,解决单次复杂问题能力强。两者需求并非完全匹配,深度学习需要一种替代硬件来满足海量数据的运算需求。<br/><br/>
        GPU:较成熟生态系统,最先收益人工智能爆发。GPU与CPU类似,只不过是一种专门进行图像运算工作的微处理器。GPU是专为执行复杂的数学和几何计算而设计的,这些计算是图形渲染所必需的。GPU在浮点运算、并行计算等部分计算方面可以提供数十倍乃至于上百倍于CPU的性能。英伟达公司从2006年下半年已经开始陆续推出相关的硬件产品以及软件开发工具,目前是人工智能硬件市场的主导。<br/><br/>
        GPU天然具有三个方面局限性。GPU作为图像处理器,设计初衷是为了应对图像处理中需要大规模并行计算。因此,其在应用于深度学习算法时,有三个方面的局限性:1.应用过程中无法充分发挥并行计算优势。2.硬件结构固定不具备可编程性。3.运行深度学习算法能效远低于ASIC及FPGA。<br/><br/>
        FPGA:能效中等、灵活度高、成本较高的AI白板,具有三类局限。FPGA称为现场可编程门阵列,用户可以根据自身的需求进行重复编程,与GPU、CPU相比,具有性能高、能耗低、可硬件编程的特点。同时具有三类局限:1.基本单元的计算能力有限;2.速度和功耗有待提升;3、FPGA价格较为昂贵。<br/><br/>
        ASIC:顶级能耗、拥抱未来。ASIC是一种为专门目的而设计的集成电路。专为特定目的而设计。不同于GPU和FPGA的灵活性,定制化的ASIC一旦制造完成将不能更改,所以初期成本高、开发周期长的使得进入门槛高。目前,大多是具备AI算法又擅长芯片研发的巨头参与,如Google的TPU。由于完美适用于神经网络相关算法,ASIC在性能和功耗上都要优于GPU和FPGA,TPU1是传统GPU性能的14-16倍,NPU是GPU的118倍。寒武纪已发布对外应用指令集,预计ASIC将是未来AI芯片的核心。<br/><br/>
        推荐标的:中科曙光(寒武纪深度合作伙伴,预计AI服务器将深度合作、X86芯片若突破则提升市场份额与毛利率)、中科创达(华为麒麟970芯片人脸识别应用提供方)、富瀚微(安防行业解码芯片领军)</p>
</div>