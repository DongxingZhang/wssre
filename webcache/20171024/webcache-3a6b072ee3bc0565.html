<div class="blk_container">
    <p> DeepMind在《Natre》上公布最新版AlphaGo<br/><br/>
        10月18日,DeepMind 在《Natre》上公布了他们最新版AlphaGo论文,介绍了迄今最强最新的版本AlphaGo
        Zero,使用纯强化学习,将价值网络和策略网络整合为一个架构,3天训练后就以100比0击败了上一版本的AlphaGo。(消息来源:新智元)<br/><br/>
        AlphaGoZero主要算法原理:强化学习、蒙特卡洛树、神经网络<br/><br/>
        左右互博,AlphaGo自我博弈提升棋力。AlphaGo
        Zero在进行了3天的自我训练后,在100局比赛中以100:0击败了上一版本的AlphaGo――而上一版本的AlphaGoLee击败了曾18次获得围棋世界冠军的韩国九段棋士李世h。经过40 天的自我训练后,AlphaGo
        Zero 变得更加强大,超越了“Master”版本的AlphaGo――Master 曾击败世界上最优秀的棋士、世界第一的柯洁。<br/><br/>
        无为而无不为,AlphaGo放弃人类围棋知识。使用了纯强化学习(不是监督学习),没有借助人类样本标注。AlphaGo Zero没有再利用人类历史棋局,训练过程从完全随机开始,AlphaGo
        Zero是在双方博弈训练过程中尝试解决对人类标注样本的依赖,以前其他版本的AlphaGo,都经过人类知识的训练,它们被告知人类高手如何下棋。而最新发布的AlphaGo
        Zero使用了更多原理和算法,从0开始,使用随机招式,40天后成为围棋界的绝世高手。<br/><br/>
        AlphaGoZero使用了神经网络、蒙特卡洛树和强化学习,使围棋趋近最优解。由于暴力枚举算法的不可行,前几代AlphaGo采用了卷积神经网络(采用一个策略网络PolicyNet和一个价值网络ValeNet)、蒙特卡洛树、监督学习和强化学习。<br/><br/>
        强化学习的应用前景<br/><br/>
        强化学习更贴切人类学习本质,应用前景广泛。(深度)强化学习适用于解决有限维度、有反馈,需要做出(连续)决策的相关应用,如自动驾驶、机器人、广告投放、金融投资、动态定价、动态治疗,以及其他前沿科学领域(预测蛋白质分子的形状,设计新材料和进行气候建模。)<br/><br/>
        投资建议<br/><br/>
        A股:科大讯飞(语音处理)、中科创达(嵌入式AI)、海康威视(图像处理)、中科曙光(AI芯片);<br/><br/>
        美股:百度(自然语言处理、自动驾驶)、英伟达(GPU深度学习生态)、谷歌(自然语言处理、自动驾驶、前沿科技);<br/><br/>
        一级市场:深鉴科技(AI芯片)、地平线机器人(自动驾驶)、商汤科技(图像处理)、云知声(语音处理)等。<br/><br/>
        风险提示:AI技术和应用进展不及预期;竞争加剧。</p>
</div>