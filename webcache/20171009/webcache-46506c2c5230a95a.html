<div class="blk_container">
    <p> 重要观息:<br/><br/>
        百度MDL支持iOSGPU,在同类框架对比中性能出色。<br/><br/>
        2017年9月25日,百度在GitHub开源移动端深度学习框架mobile-deep-learning(MDL)的全部代码以及脚本。MDL框架主要包括模型转换模块(MDLConverter)、模型加载模块(Loader)、网络管理模块(Net)、矩阵运算模块(Gemmers)及供Android端调用的JNI接层(JNIInterfaces)。MDL从立项到开源已经迭代了一年多,在移动端关注的多个指标都表现良好,如体积、功耗、速度等。随着移动端设备运算性能的提升,GPU在未来移动端运算领域将会承担非常重要的角色。目前MDL已经支持iOSGPU运行,iOSlO以上版本机型均可以使用。MDL后面也将加入GPU的Feature实现,基于OpenCL的Android平台GPU运算会让高端机型的运算性能再提升一个台阶。<br/><br/>
        移动端部署神经网络是AI行业的兵家必争之地。<br/><br/>
        在移动端部署神经网络的方式主要有两种,其一是完全在客户端运行神经网络,其二是运算神经网络过程依赖互联网,客户端只负责UI展示。第一种方式的优点是不需要经过网络,如果能保证运行速度,用户体验会非常流畅。第二种方式的优点是实现相对容易,开发成本更低。在客户端神经网络落地之前,绝大部分App都使用了运算在服务端、展示在客户端的方式。主流的移动端深度学习框架主要有苹果的CoreML、谷歌的TensorFlowLite以及比较流行的Facebook的Caffe2系列。CoreML直接对接苹果的Xcode集成开发环境,模型具有易用性,但是并未开源。谷歌出于开发人员对移动端深度学习工具的需求推出了TensorFlowLite,但是目前的TensorFlowLite在模型适配和处理速度上还需要进一步优化。<br/><br/>
        Facebook的移动端深度学习框架CaffeGo出现更早,今年Facebook更发布了Caffe2正式支持移动平台,可以在iOS、Android以及RaspberryPi上通过几行代码来训练和部署轻量化模型。比较而言,TensorFlowLite和Caffe2更适合进阶的开发人员使用,而亚马逊的AWS和苹果的CoreML更有益于自己的开发人员。<br/><br/>
        百度二季度业绩一鸣惊人,给予百度增持评级。<br/><br/>
        百度2017年二季度交出漂亮的财报,业绩已经一扫上年颓势回到巅峰状态。可以看到二季度净利润同比增长82.9%,环比增长148.5%,EPS来到了2005年上市以来环比最高增速144%,同比也达到了较高增速72.4%。<br/><br/>
        大幅增长的数字一方面是因为2016年和2017年一季度基数较低,更重要的是百度提出:“科技让复杂的世界更简单”重塑公司内部文化。通过7月5日的百度AI开发者大会,传递了百度作为一家人工智能公司的超级决心。</p>
</div>