<div class="blk_container">
    <p>
        AlphaGoZero表现惊艳,仅40天即超越此前所有版本:根据DeepMind在Nature上发表的论文MasteringtheGameofGowithoutHumanKnowledge,在只输入游戏规则和比赛目标的条件下,AlphaGoZero基于强化学习(reinforcementlearning)算法从头开始学习围棋,经过短短3天时间便以100:0的比分完胜此前击败世界冠军李世石的AlphaGoLee。在击败Lee之前,Zero进行了490万次的自我对弈,而Lee达到该水平则是经过数月的训练。经过21天的学习,Zero已达到曾击败柯洁的AlphaGoMaster的水准,仅仅40天后便以90%的胜率完全实现了超越。<br/><br/>
        纯强化学习成为亮点,或预示数据重要性下降:与此前版本的AlphaGo采用监督学习不同,Zero采用单纯的强化学习算法,完全不需依赖人类的棋谱数据进行训练,仅通过自我对弈进行学习。技术层面,一是Zero将此前版本中的策略网络和价值网络合二为一,单一神经网络使得Zero获得了更高效的训练和评估;二是Zero并不采用此前版本快速、随机的走子方法预测胜率,而是依靠高质量的神经网络评估对弈局势。另一点值得注意的是,深度强化学习极其不稳定、易遗忘,Zero并未设置大量的历史checkpoint来解决这个问题,而是采用简单的、基于梯度更新的方法来进行迭代,以更佳的渐进性能实现了网络的收敛。<br/><br/>
        我们认为,纯强化学习应用是Zero的最大亮点,这使得AI可以摆脱人类数据进行学习,有望大大简化AI的训练,扩大AI的应用场景,摆脱昂贵的数据获取成本的限制。实际上,从Zero超越Master的结果来看,人类的经验数据反而可能是对AI的制约,单纯的自我学习或更可能超越人类。<br/><br/>
        Zero仅由4个TPU支持,证明AI算法的核心地位:硬件方面,曾击败樊麾的AlphaGoFan使用了176个GPU,Lee使用了48个TPU,而Master和Zero仅使用了4个TPU。以此来看,尽管Lee具有远超Zero的硬件算力,但依靠更优的算法,Zero仍仅用3天即超越了Lee的表现。这或许表明即使在AI时代,算法仍然处于核心地位,是提高效率、降低能耗的关键。
    </p>
</div>